{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/duynguyen/spark-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PythonSVDExample, master=local[*]) created by __init__ at <ipython-input-4-f8992841a1cc>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-3e33e97de362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRowMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# $example off$\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PythonSVDExample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/duynguyen/spark-master/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/home/duynguyen/spark-master/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 299\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PythonSVDExample, master=local[*]) created by __init__ at <ipython-input-4-f8992841a1cc>:2 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "# $example on$\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "# $example off$\n",
    "sc = SparkContext(appName=\"PythonSVDExample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U factor is:\n",
      "[-0.335408389214,-0.940513917832,-0.0541736357324,7.45058059692e-09,-1.49011611938e-08]\n",
      "[-0.543122633482,0.240035423048,-0.804612205154,0.0,-7.45058059692e-09]\n",
      "[-0.769752568976,0.240450755968,0.591324290478,0.0,-2.98023223877e-08]\n",
      "Singular values are: [12.8217050658,4.81250330918,2.53844265354,9.17848613194e-08,5.12422751202e-08]\n",
      "V factor is:\n",
      "DenseMatrix([[-0.35101914,  0.10417862,  0.27650777,  0.87978099,  0.12434323],\n",
      "             [-0.13079711, -0.97715665, -0.10670644,  0.10722581, -0.07192613],\n",
      "             [-0.12707888,  0.14963237, -0.95091241,  0.23598501, -0.03921457],\n",
      "             [-0.58196805,  0.10842972,  0.08712021, -0.16150041, -0.78478269],\n",
      "             [-0.71052222,  0.01283961, -0.01824422, -0.36430307,  0.6016176 ]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext(appName=\"PythonSVDExample\")\n",
    "\n",
    "    # $example on$\n",
    "    rows = sc.parallelize([\n",
    "#         Vectors.sparse(5, {1: 1.0, 3: 7.0}),\n",
    "        Vectors.dense(1.0, 5.0, 0.0, 2.0, 3.0),\n",
    "        Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),\n",
    "        Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0)\n",
    "    ])\n",
    "\n",
    "    mat = RowMatrix(rows)\n",
    "\n",
    "    # Compute the top 5 singular values and corresponding singular vectors.\n",
    "    svd = mat.computeSVD(5, computeU=True)\n",
    "    U = svd.U       # The U factor is a RowMatrix.\n",
    "    s = svd.s       # The singular values are stored in a local dense vector.\n",
    "    V = svd.V       # The V factor is a local dense matrix.\n",
    "    # $example off$\n",
    "    collected = U.rows.collect()\n",
    "    print(\"U factor is:\")\n",
    "    for vector in collected:\n",
    "        print(vector)\n",
    "    print(\"Singular values are: %s\" % s)\n",
    "    print(\"V factor is:\\n%s\" % V)\n",
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = mat.rows.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Improper number of dimensions to norm.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-814708c70763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNorm_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/duynguyen/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Improper number of dimensions to norm.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Improper number of dimensions to norm."
     ]
    }
   ],
   "source": [
    "Norm_A = np.linalg.norm(V,ord='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute 'toDF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-b6d149f1e82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     ).toBlockMatrix(rowsPerBlock, colsPerBlock)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmatrixC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_block_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmatrixD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_block_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrixC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrixD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-b6d149f1e82d>\u001b[0m in \u001b[0;36mas_block_matrix\u001b[0;34m(rdd, rowsPerBlock, colsPerBlock)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mas_block_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowsPerBlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsPerBlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     return IndexedRowMatrix(\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzipWithIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexedRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ).toBlockMatrix(rowsPerBlock, colsPerBlock)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/duynguyen/spark-master/python/pyspark/mllib/linalg/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rows, numRows, numCols)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# both be easily serialized.  We will convert back to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m# IndexedRows on the Scala side.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             java_matrix = callMLlibFunc(\"createIndexedRowMatrix\", rows.toDF(),\n\u001b[0m\u001b[1;32m    508\u001b[0m                                         long(numRows), int(numCols))\n\u001b[1;32m    509\u001b[0m         elif (isinstance(rows, JavaObject)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute 'toDF'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "C = np.arange(1024 ** 2, dtype=np.float64).reshape(1024, 1024)\n",
    "D = np.arange(1024 ** 2, dtype=np.float64).reshape(1024, 1024)\n",
    "\n",
    "from pyspark.mllib.linalg.distributed import *\n",
    "\n",
    "def as_block_matrix(rdd, rowsPerBlock=1024, colsPerBlock=1024):\n",
    "    return IndexedRowMatrix(\n",
    "        rdd.zipWithIndex().map(lambda xi: IndexedRow(xi[1], xi[0]))\n",
    "    ).toBlockMatrix(rowsPerBlock, colsPerBlock)\n",
    "\n",
    "matrixC = as_block_matrix(sc.parallelize(C))\n",
    "matrixD = as_block_matrix(sc.parallelize(D))\n",
    "product = matrixC.multiply(matrixD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'DenseMatrix' and 'DenseMatrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bcf8c3f701d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'DenseMatrix' and 'DenseMatrix'"
     ]
    }
   ],
   "source": [
    "np.dot(V,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_s = np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_V = V.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.dot(temp_s,temp_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sc.parallelize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = RowMatrix(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.50066393208,1.33574753618,3.54530106761,11.2802923816,1.59429219727]\n",
      "[-0.629461516521,-4.70256958916,-0.513525095532,0.516024562279,-0.346144747922]\n",
      "[-0.322582445593,0.379833186855,-2.41383661546,0.599034405298,-0.0995439420233]\n",
      "[-5.34158569864e-08,9.95220692798e-09,7.99631616664e-09,-1.48232923944e-08,-7.20311703185e-08]\n",
      "[-3.64087749578e-08,6.57930699292e-10,-9.34875207151e-10,-1.86677183883e-08,3.08282547557e-08]\n"
     ]
    }
   ],
   "source": [
    "for vector in B.rows.collect():\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.50066393e+00,   1.33574754e+00,   3.54530107e+00,\n",
       "          1.12802924e+01,   1.59429220e+00],\n",
       "       [ -6.29461517e-01,  -4.70256959e+00,  -5.13525096e-01,\n",
       "          5.16024562e-01,  -3.46144748e-01],\n",
       "       [ -3.22582446e-01,   3.79833187e-01,  -2.41383662e+00,\n",
       "          5.99034405e-01,  -9.95439420e-02],\n",
       "       [ -5.34158570e-08,   9.95220693e-09,   7.99631617e-09,\n",
       "         -1.48232924e-08,  -7.20311703e-08],\n",
       "       [ -3.64087750e-08,   6.57930699e-10,  -9.34875207e-10,\n",
       "         -1.86677184e-08,   3.08282548e-08]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = RowMatrix(sc.parallelize(np.dot(np.diag(s),V.toArray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.50066393208,1.33574753618,3.54530106761,11.2802923816,1.59429219727]\n",
      "[-0.629461516521,-4.70256958916,-0.513525095532,0.516024562279,-0.346144747922]\n",
      "[-0.322582445593,0.379833186855,-2.41383661546,0.599034405298,-0.0995439420233]\n",
      "[-5.34158569864e-08,9.95220692798e-09,7.99631616664e-09,-1.48232923944e-08,-7.20311703185e-08]\n",
      "[-3.64087749578e-08,6.57930699292e-10,-9.34875207151e-10,-1.86677183883e-08,3.08282547557e-08]\n"
     ]
    }
   ],
   "source": [
    "for vector in B.rows.collect():\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RowMatrix' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7ae5d3186943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'RowMatrix' object does not support indexing"
     ]
    }
   ],
   "source": [
    "U.multiply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector1 = Vectors.dense(1.0, 5.0, 0.0, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1.numNonzeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import zeros, max, sqrt, isnan, isinf, dot, diag, count_nonzero, where\n",
    "count_nonzero(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2 = Vectors.sparse(5, {1: 1.0, 3: 7.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2.numNonzeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mat.rows.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([1.0, 5.0, 0.0, 2.0, 3.0]),\n",
       " DenseVector([2.0, 0.0, 3.0, 4.0, 5.0]),\n",
       " DenseVector([4.0, 0.0, 0.0, 6.0, 7.0]),\n",
       " DenseVector([1.0, 5.0, 0.0, 2.0, 3.0]),\n",
       " DenseVector([2.0, 0.0, 3.0, 4.0, 5.0]),\n",
       " DenseVector([4.0, 0.0, 0.0, 6.0, 7.0])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.rows.union(mat.rows).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([1.0, 5.0, 0.0, 2.0, 3.0]),\n",
       " DenseVector([2.0, 0.0, 3.0, 4.0, 5.0]),\n",
       " DenseVector([4.0, 0.0, 0.0, 6.0, 7.0])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketchMatrix = zeros((5,5))\n",
    "sketchMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sM = RowMatrix(sc.parallelize(sketchMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " DenseVector([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " DenseVector([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " DenseVector([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " DenseVector([0.0, 0.0, 0.0, 0.0, 0.0])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sM.rows.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(sM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.linalg.distributed.SingularValueDecomposition at 0x7f178e907f60>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
